{
  "cells": [
    {
      "metadata": {
        "_uuid": "1c728098629e1301643443b1341556a15c089b2b",
        "_cell_guid": "86b26423-563a-4fa1-a595-89e25ff93089",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\nfrom xgboost import XGBRegressor\n#from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.ensemble.partial_dependence import partial_dependence, plot_partial_dependence\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import cross_val_score\n\ntrain_file_path = '../input/train.csv'\ntest_file_path = '../input/test.csv'\nsubm_sample_file_path = '../input/sample_submission.csv'\n\ntrain_data = pd.read_csv(train_file_path)\ntest_data = pd.read_csv(test_file_path)\nsample_submission = pd.read_csv(subm_sample_file_path)\n\nmy_pipeline = make_pipeline(Imputer(), GradientBoostingRegressor())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f422687dc4d4b875b7018c755d096869654ce990",
        "scrolled": true,
        "_cell_guid": "52ec402c-61b6-47d8-be48-e688e19a4a26",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "y_train = train_data['SalePrice']\ndel train_data['SalePrice']\n\n#predictors = ['FullBath', 'BedroomAbvGr','LotArea', 'YearBuilt', 'GarageCars','Fireplaces', 'OverallCond', 'KitchenAbvGr', 'GrLivArea']\n#x_train = train_data[predictors]\n#X_test = test_data[predictors]\nx_train = train_data\nX_test = test_data\n#x_train.columns",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d44f5929750b70f1e4c7250bac61aaec15520b90",
        "_cell_guid": "aea8c629-ab63-4119-a8ea-2db61912b9c9",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# One hot encoding for categorical data.\n# this should be done before imputation\n\none_hot_encoded_training = pd.get_dummies(x_train)\none_hot_encoded_test = pd.get_dummies(X_test)\nx_train_OHE, X_test = one_hot_encoded_training.align(one_hot_encoded_test,\n                                                                    join='left', \n                                                                    axis=1)\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b896a70613427c4905dd65bd6b62fd4e17cee0c9",
        "_cell_guid": "7e3e7ba8-a228-488c-badc-e60ec7d5ee15",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#this function splits the training data to generate some cross validation data\n#X_train, X_val, Y_train, Y_val = train_test_split(x_train_OHE, y_train, train_size=0.3)\n\n#cross val performed without train_test_split\nscores = cross_val_score(my_pipeline, x_train_OHE, y_train, scoring='neg_mean_absolute_error')\nprint(scores)\nprint('Mean Absolute Error %2f' %(-1 * scores.mean()))\n\n#X_train_imputed_plus = X_train.copy()\n#X_val_imputed_plus = X_val.copy()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0ee4938ac2cdc23436657c31091396f644c614cf",
        "_cell_guid": "e4919b96-099d-470f-9f00-59254a14bec0",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "my_pipeline.fit(x_train_OHE, y_train)\npredicted_prices = my_pipeline.predict(X_test)\n#submission file\nmy_submission = pd.DataFrame({'Id': test_data.Id, 'SalePrice': predicted_prices})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": false,
        "_uuid": "981ec27d251b8d4a80fbfcd57e6666d41fb208b9",
        "_kg_hide-output": false,
        "_cell_guid": "aa4b0166-9a23-4d9d-9b6b-d22102ba155e",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Replacing all Nans with a versy small number\n\n###########################################################\n# DONT REPLACE WITH JUST 0 as this is an int? (use 0. OR put .astype(np.float32)) as below\n\n#X_test_replace = x_test.fillna(0.).astype(np.float32)\n\n##############################################################\n\n\n#make sure no training examples went missing (check count)\n#X_test_replace.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4a4ecbebd77645b11d7f175c5c07cd620f84173a",
        "_cell_guid": "68895357-ca0e-498e-b594-a2de95685213",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#scoredataset function, takend from Dan B's tute\n#def score_dataset(X_train, X_test, y_train, y_test):\n#    model = RandomForestRegressor()\n#    model.fit(X_train, y_train)\n#    preds = model.predict(X_test)\n#    return mean_absolute_error(y_test, preds)\n\n# imputing variables, code taken from Dan Becker's tutorial\n\n#my_imputer = Imputer()\n#X_train_imputed = my_imputer.fit_transform(X_train)\n#X_val_imputed = my_imputer.transform(X_val)\n#X_test_imputed = my_imputer.transform(X_test)\n#print(\"Mean Absolute Error from Imputation:\")\n#print(score_dataset(X_train_imputed, X_val_imputed, Y_train, Y_val))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cc8b1aa4028c909e5e1216aab6b9ad2de22364b0",
        "_cell_guid": "1e766964-4a66-4431-a215-ea974f920392",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "#cols_with_missing = (col for col in X_train.columns \n#                                 if X_train[col].isnull().any())\n#for col in cols_with_missing:\n#    X_train_imputed_plus[col + '_was_missing'] = X_train_imputed_plus[col].isnull()\n#    X_val_imputed_plus[col + '_was_missing'] = X_val_imputed_plus[col].isnull()\n\n# Imputation\n#my_imputer = Imputer()\n#X_train_imputed_plus = my_imputer.fit_transform(X_train_imputed_plus)\n#X_val_imputed_plus = my_imputer.transform(X_val_imputed_plus)\n\n#print(\"Mean Absolute Error from Imputation while Track What Was Imputed:\")\n#print(score_dataset(X_train_imputed_plus, X_val_imputed_plus, Y_train, Y_val))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1859c0e02f8a6933c1cf2ec4cbdcac896b1f383f",
        "_cell_guid": "db23f30b-da3d-4657-9c4b-49a985d09012",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# these next few lines were using a decision tree fucntion\n#my_model = DecisionTreeRegressor(max_leaf_nodes=42)\n#my_model.fit(X_train, Y_train)\n\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8330a4abc3cbfe1d4b53e4fbf840ce8d9666c8bc",
        "_cell_guid": "544a5600-d49b-4c85-adfd-c16e44401491",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "#predictions = my_model.predict(X_val)\n#mean_absolute_error(Y_val, predictions)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9373cb14391db3b1ae1749971d2a8848c1e53835",
        "_cell_guid": "ccff71dc-78e6-4701-8ec6-8b621c84184b",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "#function written by Dan Becker to calculate mean absolute error based on number\n# of max leaf nodes selected.\n\n#def get_mae(max_leaf_nodes, predictors_train, predictors_val, targ_train, targ_val):\n#    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n#    model.fit(predictors_train, targ_train)\n#    preds_val = model.predict(predictors_val)\n#    mae = mean_absolute_error(targ_val, preds_val)\n#    return(mae)\n\n#runs a for loop that tries different ranges of max leaf nodes and outputs each values\n# MAE score, to determine most effective option\n\n#listNumbers = list(range(40, 50))\n\n#for max_leaf_nodes in listNumbers:\n#    my_mae = get_mae(max_leaf_nodes, X_train, X_val, Y_train, Y_val)\n#    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "262a498bd8c66c57ce844d3daa0c3ad191b79934",
        "_cell_guid": "f2de123f-5963-4650-aab3-5e45fde1bd58",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# uses the random forest regressor model from scikit learn. \n# Random Forest is gives better results thean the decision tree model\n\n#forest_model = RandomForestRegressor()\n#forest_model.fit(X_train_imputed, Y_train)\n#forest_predictions = forest_model.predict(X_val_imputed)\n#print(mean_absolute_error(Y_val, forest_predictions))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8b9a76228633dd9d7a39253abe36f97c3d26a00c",
        "_cell_guid": "e095ef1a-2299-429c-b743-cca8bd38d021",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# XGBoost\n\n#my_model = XGBRegressor(#n_estimators=1000, #learning_rate=0.05)\n#my_model = GradientBoostingRegressor()\n# Add silent=True to avoid printing out updates with each cycle\n#my_model.fit(X_train_imputed, Y_train, early_stopping_rounds=5, eval_set=[(X_val_imputed, Y_val)], verbose=False)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d043f2a9ef4c24c34c4561bd65696aa9fee845a3",
        "_cell_guid": "09c14587-039d-430d-bdc6-3120138b40de",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#using these partial dependency graphs, with gradientboostregressor,\n# we can determine which features have a larger effect on the trining of the model\n# as seen below, overall quality is much more significant to the price of a house than\n# lotarea is.\n\n#my_model.fit(X_train_imputed, Y_train)\n# Here we make the plot\n#my_plots = plot_partial_dependence(my_model,       \n#                                   features=[ 0, 2], # column numbers of plots we want to show\n#                                   X=X_train_imputed,            # raw predictors data.\n#                                   feature_names=['LotArea', 'YearBuilt', 'OverallQual'], # labels on graphs\n#                                   grid_resolution=10) # number of values to plot on x axis",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2c1b28c982d4a422f6f33e6ea75f78ec973c4d88",
        "scrolled": false,
        "_cell_guid": "3ffd8ff1-a32e-4a57-96ac-65a51dfb7dfc",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#predicted_prices = forest_model.predict(X_test_imputed)\n#predicted_prices = my_model.predict(X_val_imputed)\n#print(predicted_prices)\n#print(\"Mean Absolute Error : \" + str(mean_absolute_error(predicted_prices, Y_val)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0770d5785451ca4503d36be2d06986a597a4bf4c",
        "_cell_guid": "21433142-b71d-4bfc-8b91-2d24450389ef",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "#predicted_prices = my_model.predict(X_test_imputed)\n#submission file\n#my_submission = pd.DataFrame({'Id': test_data.Id, 'SalePrice': predicted_prices})\n# you could use any filename. We choose submission here\n#my_submission.to_csv('submission.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "19d7b479c5f54759909037365279b9bc395b6969",
        "_cell_guid": "07878b2d-6619-4a25-85ed-99bb92c7ced4",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d0e8c68ef52982adb396f2ff8b7fac000f21b3ca",
        "_cell_guid": "2420f437-6ddf-4ac8-ba7e-8d97c50ada19",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "pygments_lexer": "ipython3",
      "file_extension": ".py",
      "name": "python",
      "nbconvert_exporter": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      }
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}